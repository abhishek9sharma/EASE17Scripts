{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_43.model\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "\n",
    "wd=os.getcwd()\n",
    "\n",
    "#foldermain=wd+'/Experiments/'\n",
    "foldermain='../Experiments/'\n",
    "#folderpath='../EXPERIMENTS/MODELS/'\n",
    "folderpath=foldermain+'/MODELS/'\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary.load(folderpath+'MultiCore.dict')\n",
    "corpus=gensim.corpora.MmCorpus(folderpath+'MultiCoreCorpus.mm')\n",
    "modelfile=''\n",
    "# for f in os.listdir(folderpath):\n",
    "#     if('.model' in f and '.model.state' not in f):\n",
    "#         modelfile=f\n",
    "for f in os.listdir(folderpath):\n",
    "    if ('.model' in f):\n",
    "        filetype = f.split('.')[-1]\n",
    "        if filetype not in ['state','id2word','npy']:\n",
    "            modelfile = f\n",
    "print(modelfile)       \n",
    "model_test= gensim.models.ldamodel.LdaModel.load(folderpath+modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [(u'minikanren', 0.035452675),\n",
       "   (u'oper', 0.035452664),\n",
       "   (u'languag', 0.023657305),\n",
       "   (u'program', 0.02365667),\n",
       "   (u'api', 0.02365567)]),\n",
       " (1,\n",
       "  [(u'microlightj', 0.07491697),\n",
       "   (u'languag', 0.07491596),\n",
       "   (u'librari', 0.037556354),\n",
       "   (u'refer', 0.037556086),\n",
       "   (u'usag', 0.03755554)]),\n",
       " (2,\n",
       "  [(u'plugin', 0.089471005),\n",
       "   (u'uri', 0.044793587),\n",
       "   (u'horizontalnav', 0.044793587),\n",
       "   (u'jqueri', 0.044793587),\n",
       "   (u'fit', 0.02245484)]),\n",
       " (3,\n",
       "  [(u'presentzj', 0.080967374),\n",
       "   (u'github', 0.040588852),\n",
       "   (u'websit', 0.040588807),\n",
       "   (u'heart', 0.04058868),\n",
       "   (u'softwar', 0.04058866)])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show word probabilities for each topic\n",
    "X=model_test.show_topics(num_topics=50, num_words=5, log=False, formatted=False)\n",
    "test=[(x[0],[y[0] for y in x[1]]) for x in X]\n",
    "topicDesc={}\n",
    "\n",
    "for t in test:\n",
    "    topicstr=' + '.join(str(e) for e in t[1])\n",
    "    #print topicstr\n",
    "    topicDesc[t[0]]=topicstr\n",
    "\n",
    "model_test.show_topics(num_topics=50, num_words=5, log=False, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITETOFILE\n",
    "folder=foldermain+'REPOPROPS/'\n",
    "\n",
    "for k in topicDesc.keys():\n",
    "    line=str(k)+','+topicDesc[k]\n",
    "    fout=open(folder+'topickeys.csv','a')\n",
    "    fout.write(line+'\\n')\n",
    "    fout.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DOCUMENTS\n",
    "import os\n",
    "foldername=foldermain+'/FILTEREDRM/PREPROCESSED/'\n",
    "fileList = os.listdir(foldername)\n",
    "docdict={}\n",
    "for fn in fileList:\n",
    "    f = open(foldername + fn, 'r')\n",
    "    txt = str(f.read())\n",
    "    docdict[fn]=txt.split()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND TOPIC\n",
    "import numpy as np\n",
    "docTopicDict={}\n",
    "for d in docdict.keys():\n",
    "    docProbs=model_test[[dictionary.doc2bow(docdict[d])]]\n",
    "    currrdocProb = [0]*49\n",
    "    for p in docProbs[0]:\n",
    "        currrdocProb[p[0]]=p[1]\n",
    "        doc_topic = np.array(currrdocProb)\n",
    "        topic=np.array(doc_topic).argmax()\n",
    "        docTopicDict[d.strip().replace('.txt','')]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITE DOCTOPIC TO FILES\n",
    "folder=foldermain+'REPOPROPS/'\n",
    "for k in docTopicDict:\n",
    "    line=k+','+str(docTopicDict[k])\n",
    "    fout=open(folder+'doctopic.csv','a')\n",
    "    fout.write(line+'\\n')\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DOC/proj/repo NAMEs\n",
    "#repdata=os.listdir(foldermain+'/HTMLSORG')\n",
    "repdata=os.listdir(foldermain+'/FILTEREDRM/PREPROCESSED/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINE DATA\n",
    "fnames=docTopicDict.keys()\n",
    "cnt=0\n",
    "folder=foldermain+'REPOPROPS/'\n",
    "comb=open(folder+'comb2desc.csv','a')\n",
    "for repoline in repdata:\n",
    "    #fkey=repoline.split(',')[0]\n",
    "    fkey=repoline.replace('.txt','')   \n",
    "    if(fkey in fnames):\n",
    "        currtopic=docTopicDict[fkey]\n",
    "        newline=repoline.replace('\\n','')+','+str(currtopic)+','+str(topicDesc[currtopic])\n",
    "    else:\n",
    "        newline=repoline.replace('\\n','')+',TOPICASSIGNED,TOPICWORDS'\n",
    "    comb.write(newline+'\\n')\n",
    "comb.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
